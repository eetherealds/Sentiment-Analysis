{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Library**"
      ],
      "metadata": {
        "id": "cqHnY2Y6GzrG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pertama, kita perlu mengimpor library yang dibutuhkan."
      ],
      "metadata": {
        "id": "29pUJx4aLiaw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pOAZFpWFWfs",
        "outputId": "d004cf2b-d441-437b-f31f-6ace86e7e69b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-play-scraper\n",
            "  Downloading google_play_scraper-1.2.7-py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_play_scraper-1.2.7-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: google-play-scraper\n",
            "Successfully installed google-play-scraper-1.2.7\n"
          ]
        }
      ],
      "source": [
        "!pip install google-play-scraper"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menginstal pustaka Python bernama google-play-scraper, yang berfungsi untuk mengambil data aplikasi dari Google Play Store secara otomatis, seperti nama aplikasi, rating, jumlah unduhan, dan ulasan pengguna."
      ],
      "metadata": {
        "id": "qy_kYk0NHuWh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Scraping Dataset**"
      ],
      "metadata": {
        "id": "-a_PVuq-LbeH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dalam proyek ini, kita akan melakukan proses web scraping untuk mengumpulkan dataset ulasan pengguna dari aplikasi \"Alfagift\" yang dapat diakses di Google Play Store. Tujuan utama dari scraping data ini adalah untuk memperoleh data mentah dalam bentuk komentar dan penilaian yang disampaikan oleh pengguna aplikasi secara langsung.\n",
        "\n",
        "Informasi yang dikumpulkan akan digunakan sebagai landasan untuk menganalisis pandangan dan persepsi pengguna mengenai aplikasi \"Alfagift\". Melalui komentar-komentar tersebut, kita bisa memahami beragam perspektif pengguna, baik yang positif maupun yang mengkritik."
      ],
      "metadata": {
        "id": "JFmUYzqcLoNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mengimpor library untuk ambil data aplikasi dan ulasan dari Play Store\n",
        "from google_play_scraper import app, reviews, Sort\n",
        "\n",
        "# mengambil semua ulasan pengguna dari sebuah aplikasi di Google Play Store dalam jumlah yang bisa ditentukan sendiri.\n",
        "scrapreview, continuation_reviews = reviews(\n",
        "    'com.alfamart.alfagift',          # ID aplikasi\n",
        "    lang='id',                    # mengambil ulasan dalam bahasa indonesia\n",
        "    country='id',                 # mengambil ulasan\n",
        "    sort=Sort.MOST_RELEVANT,      # mengurutkan ulasan\n",
        "    count=10000                   # mengambil jumlah maksimum ulasan\n",
        ")"
      ],
      "metadata": {
        "id": "cQ_Nb9FIMfSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mengimpor modul csv bawaan Python untuk menangani operasi baca/tulis file CSV\n",
        "import csv\n",
        "\n",
        "# membuka atau membuat file hasil scraping dalam mode tulis (w)\n",
        "with open('hasil_scraping_alfagift.csv', mode='w', newline='', encoding='utf-8') as file:\n",
        "\n",
        "    # menulis data ke file CSV\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # menulis header kolom pertama\n",
        "    writer.writerow(['Review'])\n",
        "\n",
        "    # melakukan iterasi pada daftar scrapreview\n",
        "    for review in scrapreview:\n",
        "\n",
        "        # menuliskan isi ulasan ke dalam file CSV\n",
        "        writer.writerow([review['content']])"
      ],
      "metadata": {
        "id": "wPn_xy4BSEe2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}